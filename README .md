# ğŸ’³ Credit Card Fraud Detection Project

## ğŸ“‹ Project Overview

This project implements a comprehensive machine learning pipeline to detect fraudulent credit card transactions. The system analyzes transaction patterns, customer behavior, and geographic data to identify potentially fraudulent activities with high accuracy.

## ğŸ¯ Business Problem

Credit card fraud causes billions of dollars in losses annually and undermines customer trust in financial institutions. Traditional rule-based systems often have high false positive rates, leading to legitimate transactions being declined. This project aims to build an intelligent fraud detection system that:

- Accurately identifies fraudulent transactions
- Minimizes false positives (legitimate transactions flagged as fraud)
- Processes transactions in real-time
- Provides interpretable results for fraud analysts

## ğŸ“Š Dataset Description

**Source:** Synthetic credit card transactions dataset  
**Size:** 1852394 transactions  
**Time Period:** Transaction data spanning multiple months  
**Target Variable:** `is_fraud` (binary: 0 = legitimate, 1 = fraudulent)

### Key Features:
- **Transaction Details:** Amount, date/time, transaction number
- **Card Information:** Credit card number (anonymized)
- **Customer Demographics:** Name, age, gender, location
- **Merchant Information:** Merchant name, category, location
- **Geographic Data:** Customer and merchant coordinates

### Class Distribution:
- **Legitimate Transactions:** ~99.35%
- **Fraudulent Transactions:** ~0.65%
- **Challenge:** Highly imbalanced dataset requiring specialized techniques

## ğŸ”§ Technical Implementation

### 1. Data Preprocessing Pipeline

#### **Missing Values Handling**
```python
# Geographic data: filled with median values
# Categorical data: filled with mode (most frequent)
# Target variable: missing values assumed as non-fraud
```

#### **Outlier Treatment**
```python
# Geographic outliers: Capped using IQR method
# Amount outliers: Removed only invalid values (negative/zero)
# Fraud cases: Preserved (they're the target, not outliers!)
```

#### **Data Type Corrections**
```python
# DateTime: trans_date_trans_time, dob
# Numeric: amt, lat, long, city_pop
# Categorical: merchant, category, state, etc.
```

### 2. Feature Engineering

#### **Time-Based Features**
- `hour`: Transaction hour (0-23)
- `day_of_week`: Day of week (0=Monday, 6=Sunday)
- `is_weekend`: Weekend transactions (higher risk)
- `is_night_transaction`: Transactions 10PM-6AM (higher risk)
- `is_business_hours`: Business hours transactions (9AM-5PM)
- `is_high_risk_hours`: Transactions 12AM-3AM (highest risk)

#### **Customer Demographics**
- `customer_age`: Calculated from date of birth
- `age_risk_category`: Age groups with different risk levels

#### **Geographic Features**
- `distance_km`: Distance between customer and merchant (Haversine formula)
- `is_far_transaction`: Transactions >100km from customer location
- `is_very_far_transaction`: Transactions >500km (very suspicious)

#### **Transaction Amount Features**
- `log_amount`: Log-transformed amount (handles skewness)
- `is_high_amount`: High-value transactions (>95th percentile)
- `is_low_amount`: Low-value transactions (<5th percentile)
- `is_round_amount`: Round amounts (e.g., $100.00)
- `amt_per_pop`: Amount relative to city population

#### **Velocity Features**
- `transactions_per_hour`: Number of transactions per card per hour
- `is_high_velocity`: Multiple transactions in short timeframe

#### **Risk Scoring**
- `category_risk_score`: Fraud rate by merchant category
- `is_high_risk_category`: Categories with high fraud rates

#### **Encoded Categorical Features**
- `merchant_encoded`: Label-encoded merchant names
- `category_encoded`: Label-encoded transaction categories
- `state_encoded`: Label-encoded states
- `job_encoded`: Label-encoded customer jobs
- `gender_encoded`: Binary encoding (0=Female, 1=Male)

### 3. Feature Selection

**Correlation-Based Selection:**
- Removed features with correlation > 0.9
- Avoided multicollinearity issues
- Retained ~30 most predictive features

### 4. Data Splitting & Scaling

**Train/Test Split:**
- 80% training, 20% testing
- Stratified split to maintain fraud ratio
- Random state = 42 for reproducibility

**Scaling:**
- **RobustScaler** (better for outliers in fraud data)
- Fitted on training data only
- Applied to both train and test sets

## ğŸ¯ Model Performance Metrics

For imbalanced fraud detection, we focus on:

- **Precision:** How many predicted frauds are actually fraud (minimize false alarms)
- **Recall:** How many actual frauds we catch (minimize missed fraud)
- **F1-Score:** Balanced measure of precision and recall
- **ROC-AUC:** Overall model discrimination ability
- **Confusion Matrix:** Detailed breakdown of predictions

## ğŸ“ Project Structure

```
fraud-detection/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ fraudTrain.csv              # Training dataset
â”‚   â”œâ”€â”€ fraudTest.csv               # Test dataset
â”‚   â””â”€â”€ preprocessed_fraud_data.csv # Cleaned dataset
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb                # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb      # Data preprocessing
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb # Feature creation
â”‚   â”œâ”€â”€ 04_modeling.ipynb           # Model training & evaluation
â”‚   â””â”€â”€ 05_results_analysis.ipynb   # Results interpretation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py            # Data preprocessing functions
â”‚   â”œâ”€â”€ feature_engineering.py     # Feature creation functions
â”‚   â”œâ”€â”€ models.py                   # Model definitions
â”‚   â””â”€â”€ evaluation.py              # Evaluation metrics
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ fraud_detection_model.pkl   # Trained model
â”‚   â”œâ”€â”€ robust_scaler.pkl          # Feature scaler
â”‚   â””â”€â”€ label_encoders.pkl         # Categorical encoders
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ feature_importance.png     # Feature importance plot
â”‚   â”œâ”€â”€ roc_curves.png             # ROC curves comparison
â”‚   â””â”€â”€ confusion_matrix.png       # Confusion matrix
â”‚
â””â”€â”€ README.md                       # This file
```

## ğŸš€ Getting Started

### Prerequisites
```bash
pip install pandas numpy scikit-learn matplotlib seaborn
pip install xgboost  # optional, for XGBoost models
```

### Running the Project

1. **Data Preprocessing:**
```python
# Load and clean the data
df = load_data()
df_clean = preprocess_data(df)
```

2. **Feature Engineering:**
```python
# Create predictive features
df_features = create_features(df_clean)
```

3. **Model Training:**
```python
# Train and evaluate models
X_train, X_test, y_train, y_test = prepare_data(df_features)
model = train_model(X_train, y_train)
evaluate_model(model, X_test, y_test)
```

## ğŸ“ˆ Key Results & Insights

### Most Important Features for Fraud Detection:
1. **Transaction Amount Features:** `log_amount`, `is_high_amount`
2. **Geographic Features:** `distance_km`, `is_far_transaction`
3. **Time Features:** `is_night_transaction`, `hour`
4. **Velocity Features:** `transactions_per_hour`, `is_high_velocity`
5. **Risk Scores:** `category_risk_score`, `merchant_risk_score`

### Business Insights:
- **Night transactions** (10PM-6AM) have 3x higher fraud rate
- **High-velocity** transactions (multiple per hour) are highly suspicious
- **Geographic distance** is a strong fraud indicator
- **Certain merchant categories** have significantly higher fraud rates
- **Round amounts** and **high amounts** are more likely to be fraudulent

## ğŸ”® Future Improvements

1. **Advanced Models:**
   - Deep learning approaches (Neural Networks)
   - Ensemble methods (Gradient Boosting)
   - Real-time streaming models

2. **Feature Enhancement:**
   - Time series features (spending patterns)
   - Network analysis (merchant connections)
   - Anomaly detection features

3. **Production Deployment:**
   - Real-time scoring API
   - Model monitoring and drift detection
   - Automated retraining pipeline

4. **Business Integration:**
   - Risk-based authentication
   - Dynamic transaction limits
   - Fraud analyst dashboard

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/new-feature`)
3. Commit your changes (`git commit -am 'Add new feature'`)
4. Push to the branch (`git push origin feature/new-feature`)
5. Create a Pull Request

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Dataset providers for the synthetic credit card data
- Scikit-learn community for machine learning tools
- Open source contributors to the fraud detection community



---

**âš ï¸ Disclaimer:** This project uses synthetic data for educational purposes. In production fraud detection systems, additional privacy and security measures are required.
